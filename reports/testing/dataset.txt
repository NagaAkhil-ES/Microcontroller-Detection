# Sample output without transforms
img
<class 'torch.Tensor'> torch.float32 torch.Size([3, 600, 800]) tensor(0.0118) tensor(0.9882)

boxes
<class 'torch.Tensor'> torch.float32 torch.Size([1, 4]) tensor([[317., 265., 556., 342.]])

labels
<class 'torch.Tensor'> torch.int64 torch.Size([1]) tensor([1])

area
<class 'torch.Tensor'> torch.float32 torch.Size([1]) tensor([18403.])

iscrowd
<class 'torch.Tensor'> torch.int64 torch.Size([1]) tensor([0])

image_id
<class 'torch.Tensor'> torch.int64 torch.Size([1]) tensor([101826]) 


# transforms

train transforms 
 Compose([
  Resize(always_apply=False, p=1, height=200, width=200, interpolation=1),
  Normalize(always_apply=False, p=1.0, mean=[0.2947157025337219, 0.21146990358829498, 0.2231939733028412], 
            std=[0.29502108693122864, 0.23328842222690582, 0.24320556223392487], max_pixel_value=255.0),
  ToTensorV2(always_apply=True, p=1.0, transpose_mask=False),
], p=1.0, bbox_params={'format': 'pascal_voc', 'label_fields': ['labels'], 
'min_area': 0.0, 'min_visibility': 0.0, 'check_each_transform': True}, keypoint_params=None, additional_targets={})

test transforms 
 Compose([
  Resize(always_apply=False, p=1, height=200, width=200, interpolation=1),
  Normalize(always_apply=False, p=1.0, mean=[0.2947157025337219, 0.21146990358829498, 0.2231939733028412], 
  std=[0.29502108693122864, 0.23328842222690582, 0.24320556223392487], max_pixel_value=255.0),
  ToTensorV2(always_apply=True, p=1.0, transpose_mask=False),
], p=1.0, bbox_params={'format': 'pascal_voc', 'label_fields': ['labels'], 
'min_area': 0.0, 'min_visibility': 0.0, 'check_each_transform': True}, keypoint_params=None, additional_targets={})

# Sample output with transforms h=200, w=200 without norm

img
<class 'torch.Tensor'> torch.float64 torch.Size([3, 200, 200]) tensor(0.0196, dtype=torch.float64) tensor(0.9137, dtype=torch.float64) 

boxes
<class 'torch.Tensor'> torch.float32 torch.Size([1, 4]) tensor([[ 79.2500,  88.3333, 139.0000, 114.0000]]) 

labels
<class 'torch.Tensor'> torch.int64 torch.Size([1]) tensor([1]) 

area
<class 'torch.Tensor'> torch.float32 torch.Size([1]) tensor([1533.5831]) 

iscrowd
<class 'torch.Tensor'> torch.int64 torch.Size([1]) tensor([0]) 

image_id
<class 'torch.Tensor'> torch.int64 torch.Size([1]) tensor([101826]) 



# Sample output with transforms h=600, w=800 without norm

(env) ps40012941@dell-mys-gpu:~/mc_detection$ python src/data/dataset.py
img
<class 'torch.Tensor'> torch.float64 torch.Size([3, 600, 800]) tensor(0.0118, dtype=torch.float64) tensor(0.9882, dtype=torch.float64) 

boxes
<class 'torch.Tensor'> torch.float32 torch.Size([1, 4]) tensor([[317., 265., 556., 342.]]) 

labels
<class 'torch.Tensor'> torch.int64 torch.Size([1]) tensor([1]) 

area
<class 'torch.Tensor'> torch.float32 torch.Size([1]) tensor([18403.]) 

iscrowd
<class 'torch.Tensor'> torch.int64 torch.Size([1]) tensor([0]) 

image_id
<class 'torch.Tensor'> torch.int64 torch.Size([1]) tensor([101826]) 


# Sample output with transforms frame shape = 200,200 and with norm

img
<class 'torch.Tensor'> torch.float32 torch.Size([3, 200, 200]) tensor(-0.8793) tensor(2.7581) 

boxes
<class 'torch.Tensor'> torch.float32 torch.Size([1, 4]) tensor([[ 79.2500,  88.3333, 139.0000, 114.0000]]) 

labels
<class 'torch.Tensor'> torch.int64 torch.Size([1]) tensor([1]) 

area
<class 'torch.Tensor'> torch.float32 torch.Size([1]) tensor([1533.5831]) 

iscrowd
<class 'torch.Tensor'> torch.int64 torch.Size([1]) tensor([0]) 

image_id
<class 'torch.Tensor'> torch.int64 torch.Size([1]) tensor([101826]) 